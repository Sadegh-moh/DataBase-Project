docker compose up -d
curl.exe http://127.0.0.1:9200     # should return cluster info


1) Create the index & pipeline

# if the index exists, delete it first (ignore errors if not found)
curl.exe -X DELETE "http://127.0.0.1:9200/amazon-music-reviews"

# create the index from your file
curl.exe -X PUT "http://127.0.0.1:9200/amazon-music-reviews" `
  -H "Content-Type: application/json" `
  --data-binary "@mappings/amazon-music.json"


1B) Ingest pipeline
curl.exe -X PUT "http://127.0.0.1:9200/_ingest/pipeline/compute_fields" `
  -H "Content-Type: application/json" `
  --data-binary "@pipelines/compute_fields.json"

Quick check

curl.exe "http://127.0.0.1:9200/amazon-music-reviews/_mapping?pretty"


2) Preprocess the dataset → JSONL

# regenerate JSONL in UTF-8 (PowerShell-safe)
python .\src\parse_stream.py --input .\Music.txt.gz --require-both | `
Out-File -Encoding utf8 .\reviews.ndjson

3) Bulk ingest into OpenSearch

python .\src\bulk_ingest.py --index amazon-music-reviews `
  --jsonl .\reviews.ndjson --pipeline compute_fields

3) Verify ingest worked
curl.exe "http://127.0.0.1:9200/amazon-music-reviews/_count"
curl.exe "http://127.0.0.1:9200/amazon-music-reviews/_search?size=1"


# run all queries, return up to 100 hits for the hit-based ones, save to outputs/
python .\src\run_queries.py --q all --size 100
or
python .\src\run_queries.py --q q3

# or crank hits higher if you want:
python .\src\run_queries.py --q all --size 500

or
curl.exe -s -X POST "http://127.0.0.1:9200/amazon-music-reviews/_search" `
  -H "Content-Type: application/json" --data-binary "@queries\q5.json"


5) Baseline performance (latency/throughput)
python .\src\bench.py --duration 20 --concurrency 4 8 12 16 20 24 32 40 48 --host http://127.0.0.1:9200 --index amazon-music-reviews --out-json .\bench_base.json --out-csv .\bench_base.csv

for the queries:

$qs = 'q1','q2','q3','q4','q5','q6','q7','q8','q9','q10','q11'
foreach ($q in $qs) {
  python .\src\bench.py --duration 20 --concurrency 4 8 12 16 20 24 32 40 48 `
    --query-file ".\queries\$q.json" `
    --host http://127.0.0.1:9200 --index amazon-music-reviews `
    --out-json ".\outputs\${q}_bench.json" --out-csv ".\outputs\${q}_bench.csv"
}

6) “Optimization” pass and compare

Create the JSON file (exact double quotes, no smart quotes):
@"
{
  "index": {
    "refresh_interval": "60s",
    "number_of_replicas": 0
  }
}
"@ | Set-Content -Encoding ascii .\optimize_settings.json


6A) Tune index settings (no schema change)
# Switch to ingest-friendly settings (less refresh, no replicas)
curl.exe -s -X PUT "http://127.0.0.1:9200/amazon-music-reviews/_settings" `
  -H "Content-Type: application/json" `
  --data-binary "@optimize_settings.json"

Now search-optimized (after ingest), revert refresh:
@"
{
  "index": {
    "refresh_interval": "1s"
  }
}
"@ | Set-Content -Encoding ascii .\set_refresh_1s.json


Then :

curl.exe -s -X PUT "http://127.0.0.1:9200/amazon-music-reviews/_settings" `
  -H "Content-Type: application/json" `
  --data-binary "@set_refresh_1s.json"


6B) Re-run the benchmark (same matrix)
$qs = 'q1','q2','q3','q4','q5','q6','q7','q8','q9','q10','q11'
foreach ($q in $qs) {
  python .\src\bench.py --duration 20 --concurrency 4 8 12 16 20 24 32 40 48 `
    --query-file ".\queries\$q.json" `
    --host http://127.0.0.1:9200 --index amazon-music-reviews `
    --out-json ".\outputs\${q}_bench_optimized.json" --out-csv ".\outputs\${q}_bench_optimized.csv"
}

6C) Compare results
Open the two JSONs and compare throughput_rps, latency_ms_avg, latency_ms_p95 per concurrency.

7) Collect ≥5 metrics the doc asks for
# Docs & store size
curl.exe "http://127.0.0.1:9200/_cat/indices?v" `
  | Out-File "metrics/metrics_indices.txt"

# Indexing totals & time
curl.exe "http://127.0.0.1:9200/amazon-music-reviews/_stats/indexing?pretty" `
  | Out-File "metrics/metrics_indexing.txt"

# Search totals & time
curl.exe "http://127.0.0.1:9200/amazon-music-reviews/_stats/search?pretty" `
  | Out-File "metrics/metrics_search.txt"

# Segments (count, memory)
curl.exe "http://127.0.0.1:9200/amazon-music-reviews/_stats/segments?pretty" `
  | Out-File "metrics/metrics_segments.txt"

# Cluster health
curl.exe "http://127.0.0.1:9200/_cluster/health?pretty" `
  | Out-File "metrics/metrics_cluster_health.txt"